{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18dc8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65f12bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyforest in c:\\users\\aarya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd9078d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from sklearn.model_selection import KFold',\n",
       " 'import glob',\n",
       " 'from sklearn.linear_model import LogisticRegression',\n",
       " 'from sklearn.ensemble import GradientBoostingClassifier',\n",
       " 'import pydot',\n",
       " 'from dask import dataframe as dd',\n",
       " 'from sklearn.feature_extraction.text import CountVectorizer',\n",
       " 'import dash',\n",
       " 'import torch',\n",
       " 'import datetime as dt',\n",
       " 'import sys',\n",
       " 'from PIL import Image',\n",
       " 'import plotly.express as px',\n",
       " 'from sklearn.model_selection import GridSearchCV',\n",
       " 'from pyspark import SparkContext',\n",
       " 'from sklearn.linear_model import RidgeCV',\n",
       " 'from sklearn.linear_model import ElasticNetCV',\n",
       " 'from sklearn.preprocessing import RobustScaler',\n",
       " 'from sklearn.impute import SimpleImputer',\n",
       " 'import xgboost as xgb',\n",
       " 'from sklearn.preprocessing import PolynomialFeatures',\n",
       " 'import keras',\n",
       " 'import tqdm',\n",
       " 'from sklearn.model_selection import cross_val_score',\n",
       " 'import lightgbm as lgb',\n",
       " 'import matplotlib as mpl',\n",
       " 'import sklearn',\n",
       " 'from sklearn.preprocessing import MinMaxScaler',\n",
       " 'from sklearn.ensemble import RandomForestClassifier',\n",
       " 'import awswrangler as wr',\n",
       " 'import seaborn as sns',\n",
       " 'from statsmodels.tsa.arima_model import ARIMA',\n",
       " 'from sklearn.decomposition import PCA',\n",
       " 'import statsmodels.api as sm',\n",
       " 'import fastai',\n",
       " 'import tensorflow as tf',\n",
       " 'from sklearn.linear_model import LinearRegression',\n",
       " 'import statistics',\n",
       " 'from fbprophet import Prophet',\n",
       " 'from sklearn.linear_model import Ridge',\n",
       " 'from sklearn import svm',\n",
       " 'from sklearn import metrics',\n",
       " 'import altair as alt',\n",
       " 'import textblob',\n",
       " 'from scipy import signal as sg',\n",
       " 'from sklearn.linear_model import Lasso',\n",
       " 'import cv2',\n",
       " 'import bokeh',\n",
       " 'from scipy import stats',\n",
       " 'import fbprophet',\n",
       " 'from sklearn.ensemble import GradientBoostingRegressor',\n",
       " 'from openpyxl import load_workbook',\n",
       " 'import spacy',\n",
       " 'import matplotlib.pyplot as plt',\n",
       " 'from sklearn.manifold import TSNE',\n",
       " 'from sklearn.model_selection import StratifiedKFold',\n",
       " 'import plotly.graph_objs as go',\n",
       " 'import imutils',\n",
       " 'from xlrd import open_workbook',\n",
       " 'from sklearn.linear_model import LassoCV',\n",
       " 'import nltk',\n",
       " 'from sklearn.linear_model import ElasticNet',\n",
       " 'import os',\n",
       " 'from sklearn.feature_extraction.text import TfidfVectorizer',\n",
       " 'import pickle',\n",
       " 'import re',\n",
       " 'from sklearn.ensemble import RandomForestRegressor',\n",
       " 'from sklearn.preprocessing import LabelEncoder',\n",
       " 'from sklearn.model_selection import RandomizedSearchCV',\n",
       " 'from sklearn.preprocessing import OneHotEncoder',\n",
       " 'import gensim',\n",
       " 'from sklearn.cluster import KMeans',\n",
       " 'from pathlib import Path',\n",
       " 'import skimage',\n",
       " 'import plotly as py']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyforest import *\n",
    "lazy_imports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81937904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('high_concrete_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbee6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['fineagg','coarseagg','ash','silica_fume','cement', 'slag','Water', 'superplastic','age', 'strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b599287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cap outliers and normalize features\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "features_to_cap = ['silica_fume', 'cement', 'slag', 'age']\n",
    "for feature in features_to_cap:\n",
    "    df[feature] = np.where(df[feature] < lower_bound[feature], lower_bound[feature], df[feature])\n",
    "    df[feature] = np.where(df[feature] > upper_bound[feature], upper_bound[feature], df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a017e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop('strength', axis=1)\n",
    "y = df['strength']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)  # Ensure feature names are carried over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df36fe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bba409c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6d675a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import train_test_split'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting Machine\n",
    "gbm_model = GradientBoostingRegressor(random_state=42)\n",
    "gbm_model.fit(X_train, y_train)\n",
    "y_pred_gbm = gbm_model.predict(X_test)\n",
    "rmse_gbm = np.sqrt(mean_squared_error(y_test, y_pred_gbm))\n",
    "r2_gbm = r2_score(y_test, y_pred_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ce7157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on new data\n",
    "# new_data = {\n",
    "#     'fineagg': [float(input(\"Fine Aggregate (kg/m^3): \"))],\n",
    "#     'coarseagg': [float(input(\"Coarse Aggregate (kg/m^3): \"))],\n",
    "#     'ash': [float(input(\"Fly ash (kg/m^3): \"))],\n",
    "#     'silica_fume': [float(input(\"Silica Fume (kg/m^3): \"))],\n",
    "#     'cement': [float(input(\"Cement (kg/m^3): \"))],\n",
    "#     'slag': [float(input(\"Slag (kg/m^3): \"))],\n",
    "#     'Water': [float(input(\"Water (kg/m^3): \"))],\n",
    "#     'superplastic': [float(input(\"Superplasticizer (kg/m^3): \"))],\n",
    "#     'age': [int(input(\"Age (days): \"))]\n",
    "# }\n",
    "# new_df = pd.DataFrame(new_data)\n",
    "# new_pred = gbm_model.predict(new_df)\n",
    "# print(\"Predicted Compressive Strength:\", new_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b252707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving best model\n",
    "import pickle\n",
    "savePath = r'C:\\Users\\aarya\\Desktop\\project_final\\linear.sav'\n",
    "pickle.dump(gbm_model,open(savePath, 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
